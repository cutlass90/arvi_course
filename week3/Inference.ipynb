{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "import train\n",
    "import tools\n",
    "from config import config as c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path_to_imgs = './facs/images/S046/002'\n",
    "path_to_imgs = './facs/images/S010/006'\n",
    "\n",
    "THRESHOLD = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded\n"
     ]
    }
   ],
   "source": [
    "model = train.get_model()\n",
    "class_to_au = {v:k for k, v in c.au_map.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = tools.find_files(path_to_imgs, '*.png')\n",
    "imgs = tools.process_imgs(paths, c, augmentation=False)\n",
    "landmarks = np.expand_dims(tools.process_landmarks(imgs, '_'), 0)\n",
    "imgs = np.expand_dims(imgs, 0).astype(float)/127.5 - 1\n",
    "imgs = np.expand_dims(imgs, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion, au = model.predict({'img_inputs': imgs, 'landmark_inputs': landmarks})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found emotion number 5  - Happiness\n"
     ]
    }
   ],
   "source": [
    "print('Found emotion number {}  - {}'.format(np.argmax(emotion)+1, c.emotion_map[np.argmax(emotion)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found action units 6.0\n",
      "Found action units 12.0\n",
      "Found action units 25.0\n"
     ]
    }
   ],
   "source": [
    "for a in np.nonzero(au[0]>THRESHOLD)[0]:\n",
    "    print('Found action units', class_to_au[a])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00170002,  0.05397355,  0.03240949,  0.11169598,  0.79552537,\n",
       "         0.00362151,  0.00107412]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('./paths.pkl', 'rb') as f:\n",
    "#     train_paths, test_paths = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# true_emo = []\n",
    "# pred_emo = []\n",
    "# for path in test_paths:\n",
    "#     # out_emotion\n",
    "#     emo_path = tools.find_files(os.path.join(c.path_to_data, 'emotions/', path), '*.txt')\n",
    "#     if len(emo_path) > 0:\n",
    "#         with open(emo_path[0], 'r') as f:\n",
    "#             class_ = int(float(f.read()[3:-1]))\n",
    "#         true_emo.append(class_)\n",
    "        \n",
    "#         img_paths = tools.find_files(os.path.join(c.path_to_data, 'images/', path), '*.png')\n",
    "#         imgs = tools.process_imgs(img_paths, c, augmentation=False)\n",
    "#         landmarks = np.expand_dims(tools.process_landmarks(imgs, '_'), 0)\n",
    "#         imgs = np.expand_dims(imgs, 0).astype(float)/127.5 - 1\n",
    "#         imgs = np.expand_dims(imgs, 4)\n",
    "#         emotion, au = model.predict({'img_inputs': imgs, 'landmark_inputs': landmarks})\n",
    "#         pred_emo.append(np.argmax(emotion))\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
